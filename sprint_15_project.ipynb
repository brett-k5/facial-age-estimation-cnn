{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "I included everything in the first notebook you provided. \n",
    "\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Hi Brett ! My name is Svetlana (my handle on Discord is `svetatripleten`). Congratulations on submitting Computer Vision project! üéâ\n",
    "    \n",
    "\n",
    "> I included everything in the first notebook you provided.\n",
    "\n",
    "\n",
    "Which notebook? Can you upload it please? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "I am a little confused - TTT provided two notebooks: one for the EDA, and another for the model training (which is this one). Each notebook had identical precode, so I just did everything in the first notebook that was there for the EDA. I will just copy and paste everything I did in that notebook to this one I guess. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "I wanted to actually train a CNN instead of just copy and pasting the ouputs from the model you guys trained. For this reason I downloaded the data set provided by ChaLearn.\n",
    "\n",
    "The original data set already had different folders for training data, validation data, and testing data. Hence, the code to load the data is different (i.e. three sets instead of one). I did not want to run an EDA on data that was different than the data I trained the model on. Therefore, I have provided the code as I ran it on the Jupyter Notebook I launched from VS code on my local device. The This means that I loaded three different sets of data. \n",
    "    \n",
    "Three other points which are worth noting: \n",
    "\n",
    "    1. Since ImageDataGenerator is deprecated I chose to design a function to accomplis the same tasks.\n",
    "    2. I ran the EDA in the Jupyter Notebook I launcehd from VS code, but I trained the model using A100 GPUs on google colab. I did it this way because there was no need to waste extra time and memory re-plotting the images every time I had to re-run all the cells to train the model again.\n",
    "    3. The code below includes code that I ran for the EDA in my local notebook first, followed by the code I used to train the model in google colab, with the exception of the load_csv() function which appears first here, but was utilized in my colab notebook not the Jupyter Notebook I used for the EDA. \n",
    "    \n",
    "If any of this is a problem feel free to send the project back, as it will not be too much trouble to run the EDA on the dataset the way it constructed on TTT, and to use ImageDataGenerator. \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "\n",
    "\n",
    "Understood. It totally makes sense! Actually, you are probably going to use PyTorch much more often. It is more flexible and preferable.\n",
    "\n",
    "\n",
    "However, I do not have the data you used, so I cannot run your code. I reviewed the code without running it, and everything looks correct. I do not see any significant issues. Great job!  \n",
    "     \n",
    "\n",
    "I used the standard color marking:\n",
    "    \n",
    "  \n",
    "    \n",
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "\n",
    "Great solutions and ideas that can and should be used in the future are in green comments. Some of them are: \n",
    "    \n",
    "    \n",
    "- You have successfully displayed and analyzed age distribution, great!\n",
    "    \n",
    "    \n",
    "- It's also a good idea to display several photos, since we need to understand what kind of data we have;\n",
    "\n",
    "    \n",
    "- You have correctly built a model; \n",
    "\n",
    "\n",
    "- Analyzed the result in the final conclusion, which is also important! The analysis usually helps us to identify the area for further improvement.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project. \n",
    " \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "    \n",
    "Issues that must be corrected to achieve accurate results are indicated in red comments. However, there are no such issues, well done!\n",
    "\n",
    "</div>\n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**To sum up:**</font> thank you very much for submitting the project! You have successfully built a model and recieved significant results, great job! Your project is great and does not have any issues that need to be fixed. Therefore, I accept the project now.\n",
    "\n",
    "\n",
    "<hr>\n",
    "    \n",
    "    \n",
    "‚úçÔ∏è Here's a nice playlist [Introduction to\n",
    "Deep Learning](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) on youtube that you may find helpful and interesting. This is another interesting [Computer Vision Playlist](https://www.youtube.com/playlist?list=PLf7L7Kg8_FNxHATtLwDceyh72QQL9pvpQ).     \n",
    " \n",
    "    \n",
    "    \n",
    "Here's a link to [AI for beginners](https://github.com/microsoft/ai-for-beginners) course by Microsoft. \n",
    "    \n",
    "<hr>\n",
    "    \n",
    "I hope you enjoyed this topic. Good luck! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convolutional Neural Network (CNN) to Help Good Seed Grocery Store Identify Underage Customers Attempting to Buy Alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good Seed Grocery Store is looking for an image recognition model that can help them avoid selling alcohol to underage customers. The goal of this project is to create a CNN which can aid them in this task. We will start by undergoing an exploratory data analysis to make sure the data is ready to be fed to the model. Then we will train, validate, and test a model comprised of a ResNet50 layer, a GlobalAveragePooling2D layer, and lastly a fully connected Dense layer without one output neuron that utilizes a relu activation function (relu is ideal for age prediction because it can only output positive values). We may make some subtle adjustements to this approach if we can see that they yield improvd performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os                              # File and path operations\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np                     # Numerical computations\n",
    "import pandas as pd                    # Data handling and analysis\n",
    "import matplotlib.pyplot as plt       # Plotting\n",
    "import seaborn as sns                  # Enhanced plotting\n",
    "import tensorflow as tf                # TensorFlow for deep learning\n",
    "from PIL import Image                 # Pillow for image file handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the `/datasets/faces/` folder, there you can find\n",
    "- The `final_files` folder with 7.6k photos\n",
    "- The `labels.csv` file with labels, with two columns: `file_name` and `real_age`\n",
    "\n",
    "Given the fact that the number of image files is rather high, it is advisable to avoid reading them all at once, which would greatly consume computational resources. We recommend you build a generator with the ImageDataGenerator generator. This method was explained in Chapter 3, Lesson 7 of this course.\n",
    "\n",
    "The label file can be loaded as an usual CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSVs containing real age and file names\n",
    "def load_csv(base_path):\n",
    "    train_df = pd.read_csv(os.path.join(base_path, 'gt_avg_train.csv'))\n",
    "    val_df = pd.read_csv(os.path.join(base_path, 'gt_avg_valid.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(base_path, 'gt_avg_test.csv'))\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "base_path = '/content/drive/MyDrive'  # change here if needed per environment\n",
    "train_df, val_df, test_df = load_csv(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that joins folder and fname, \n",
    "# while also allowing the option to use the cropped images. \n",
    "def get_file_path(base_path, folder, fname, use_cropped_faces=True):\n",
    "    if use_cropped_faces:\n",
    "        fname = fname.replace('.jpg', '.jpg_face.jpg')\n",
    "    rturn os.path.join(base_path, folder, fname)\n",
    "\n",
    "\n",
    "# Calls the get_file_path function on the 'file_name' column of each DataFrame\n",
    "train_df['file_path'] = train_df['file_name'].apply(lambda x: get_file_path('train', x))\n",
    "val_df['file_path']   = val_df['file_name'].apply(lambda x: get_file_path('valid', x))\n",
    "test_df['file_path']  = test_df['file_name'].apply(lambda x: get_file_path('test', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a look at the DataFrames with the added 'file_path' column\n",
    "print(train_df.head())\n",
    "print(val_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will load the data set iteratively (i.e. not all at once)\n",
    "# and maximizes efficiency by utilizing pre-fetching. \n",
    "def load_data(df, batch_size=32, shuffle=True):\n",
    "    file_paths = df['file_path'].values\n",
    "    labels = df['real_age'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "\n",
    "    def load_and_preprocess(path, label):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)         # Decode image\n",
    "        image = tf.image.resize(image, [224, 224])              # Resize to uniform size\n",
    "        image = image / 255.0                                   # Normalize to [0, 1]\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    image_shape = next(iter(dataset.batch(1).as_numpy_iterator()))[0].shape\n",
    "\n",
    "    if shuffle:\n",
    "        # Shuffle data set at start of each epoch (assuming shuffle=True)\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "    # Fetch a batch size of 32\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Prefetch the next set while the model is traniing on current set\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2</b>\n",
    "    \n",
    "We rarely need to define a function inside another function. It does not make the code easier to understand nor does it simplify the debugging process.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign iterative output of build_data set function to relevant data set variable\n",
    "train_ds, image_shape = load_data(train_df, batch_size=32, shuffle=True)\n",
    "val_ds, _ = load_data(val_df, batch_size=32, shuffle=False)\n",
    "test_ds, _ = load_data(test_df, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are really only interested in the 'real_age' column. Therefore, the real_age column will be the focus of our exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruct matplotlib to use seaborn presentation style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate lbabls data sets for global EDA analysis\n",
    "eda_df = pd.concat([train_df, val_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_df.info())\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_grouped_df = eda_df.groupby('real_age').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sns.boxplot(data=eda_grouped_df, x='real_age', color='lightblue')\n",
    "plt.title('Box plot of Age')\n",
    "plt.xlabel('Age')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(data=eda_df, x='real_age', bins=100, kde=True, color='lightgreen')\n",
    "plt.xticks(ticks=range(0, 101, 5))\n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is a fair representation of the distribution of age in the United States. For example, as of 2020 the most numerous age range in the United States is 15-34 which roughly corresponds to what we see in our data set. The next most common age range in the United States after 15-34 is 55-59. This is not quite reflected in our data set. In our data the most common age after any between 15 and 34 is 40, and next is 50. Given that the paper associated with this data wsa published in 2017, it is fair to think that this data was taken in 2017 or a little bit before. If taken in 2016, depending on how the months align, this could put the age 50 peak at age 55 by some month in 2020. Even still, our data set is not in perfect alignment with that of the US population in 2020, and likely does not reflect the US age population in 2025.\n",
    "\n",
    "Nevertheless, for the task at hand, our data set is appropriate. We are looking to predict the ages of people to decide if they are old enough to buy alcohol. Therefore, we want the most data points for people who are likely to buy aclohol when they are too young, and people who are old enough to buy alcohol but young looking enough so that their age appropriateness is not immediately obvious. The two most common ages in our data set are 25 and 30, with most of the next most common ages appearing between 16 and 30.\n",
    "\n",
    "I got my information about the age distribution for the United States in 2020 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a look at the training, validation, and test sets separately to make sure their distributions for the real_age column are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of names and DataFrames for easy plotting with for loops\n",
    "names = ['Train', 'Validation', 'Test']\n",
    "df_list = [train_df, val_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target variable for each set for piecewise EDA \n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, (df, name) in enumerate(zip(df_list, names)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.boxplot(data=df, x='real_age', color='lightblue')\n",
    "    plt.title(f'Box plot of Age ({name} set)')\n",
    "    plt.xlabel('Age')\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, (df, name) in enumerate(zip(df_list, names)):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.histplot(data=df, x='real_age', bins=100, kde=True, color='lightgreen')\n",
    "    plt.xticks(ticks=range(0, 101, 5))\n",
    "    plt.title(f'Histogram of Age ({name} set)')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the target variable between our training set, validation set, and test set are very similar. Therefore, our model should generalize well to the validation and test sets. Let's get a look at the data set in full. Next we will print out some images to make sure there are no obvious misalignments between the labels and the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    # Select first 15 images and corresponding labels\n",
    "    images = images[:15]\n",
    "    labels = labels[:15]\n",
    "    break\n",
    "\n",
    "# Plot the images with corresponding labels\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(images[i].numpy()) \n",
    "    plt.title(f\"Age: {int(labels[i])}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ages for our faces all appear to be appropriate, and we hae a variety of situations and lightings between images. There are no obvious biases presening themselves that would lead to overfitting. Therefore, we will leave the images as they are. Let's give the extremes of our data set a look just to make sure nothing is off with the age labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables containing images and lables for youngest 5\n",
    "# faces and oldest 5 faces\n",
    "youngest = eda_df.nsmallest(5, 'real_age')\n",
    "oldest = eda_df.nlargest(5, 'real_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to plot youngest and oldest faces\n",
    "def show_images(df, title):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    # itreate over each row for access to index and row contents\n",
    "    for i, row in enumerate(df.itertuples()):\n",
    "        \n",
    "        img = tf.io.read_file(row.file_path)           # Extract file path\n",
    "        img = tf.image.decode_jpeg(img, channels=3)    # Decode image found at file path\n",
    "        img = tf.image.resize(img, [224, 224])/255.0   # rescale image \n",
    "\n",
    "        plt.subplot(1, len(df), i+1) # We use i+1 because subplot index starts at 1, and i starts at 0. \n",
    "        plt.imshow(img.numpy())\n",
    "        plt.title(f\"Age: {int(row.real_age)}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(youngest, 'Youngest Faces')\n",
    "show_images(oldest, 'Oldest Faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, everything looks good here. Let's check the original image sizes to make sure the dimensions we rescaled to are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "size_counter = Counter()\n",
    "for path in eda_df['file_path']:\n",
    "    try:\n",
    "        with Image.open(path) as img:   # Use 'with' to presece resources\n",
    "            # Count the number of images with a given size - Counter() works by using the tuple as a key\n",
    "            size_counter[img.size] +=1\n",
    "    except Exception as e:\n",
    "        print(\"Error with {path}: {e}\")\n",
    "\n",
    "print(size_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! All of our images are square, and there are no significant outliers. Therefore, our rescaling to 224, 224 is appropriate. Now we can move on to building and training our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary functions to train your model on the GPU platform and build a single script containing all of them along with the initialization section.\n",
    "\n",
    "To make this task easier, you can define them in this notebook and run a ready code in the next section to automatically compose the script.\n",
    "\n",
    "The definitions below will be checked by project reviewers as well, so that they can understand how you built the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "\n",
    "  \"\"\"\n",
    "  It defines model\n",
    "  \"\"\"\n",
    "\n",
    "  backbone = ResNet50(weights='imagenet',\n",
    "                      input_shape=input_shape,\n",
    "                      include_top=False)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(backbone)\n",
    "  model.add(GlobalAveragePooling2D())\n",
    "  model.add(Dense(1, activation='relu'))\n",
    "\n",
    "  optimizer = Adam(learning_rate=0.0005)\n",
    "  model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2</b>\n",
    "\n",
    "\n",
    "Correct! \n",
    "    \n",
    "    \n",
    "- `Dense(1, activation='relu')` is appropriate, since you are predicting a single value. Using 1 neuron makes sense here.\n",
    "    \n",
    "    \n",
    "- Adam optimizer with learning rate 0.0005 is a solid and commonly used choice, well done. \n",
    "\n",
    "\n",
    "- The use of MSE loss and MAE as metric is also correct. MSE encourages precision, and MAE helps us interpret error scale in the same units as the target.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, val_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "  \"\"\"\n",
    "  Trains the model given the parameters\n",
    "  \"\"\"\n",
    "  if steps_per_epoch is None:\n",
    "    steps_per_epoch = len(train_data)\n",
    "\n",
    "  if validation_steps is None:\n",
    "    validation_steps = len(val_data)\n",
    "\n",
    "  checkpoint = ModelCheckpoint( # Choose the parameters that performed best on validation set\n",
    "      filepath='best.weights.h5',\n",
    "      monitor='val_loss',\n",
    "      save_best_only=True,\n",
    "      save_weights_only=True)\n",
    "\n",
    "  model.fit(train_data,\n",
    "            validation_data=val_data,\n",
    "            batch_size=batch_size, epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=[checkpoint],\n",
    "            verbose=2)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, test_target, human_estimates_avg):\n",
    "    model_mse, model_mae = model.evaluate(test_ds)\n",
    "    mae_humans = mean_absolute_error(test_target, human_estimates_avg)\n",
    "    mse_humans = mean_squared_error(test_target, human_estimates_avg)\n",
    "    print(f\"MAE for the model: {model_mae}\")\n",
    "    print(f\"MSE for the model: {model_mse}\")\n",
    "    print(f\"MAE human guess avg: {mae_humans}\")\n",
    "    print(f\"MSE human guess avg: {mse_humans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you've defined the necessary functions you can compose a script for the GPU platform, download it via the \"File|Open...\" menu, and to upload it later for running on the GPU platform.\n",
    "\n",
    "N.B.: The script should include the initialization section as well. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m f.write(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Write the source code of required functions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fn_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[43mload_csv\u001b[49m, get_file_path, load_data, create_model, train_model, model_eval]:\n\u001b[32m     40\u001b[39m     src = inspect.getsource(fn_name)\n\u001b[32m     41\u001b[39m     f.write(clean(src))  \u001b[38;5;66;03m# Clean function body too\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'load_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare a script to run on the GPU platform\n",
    "\n",
    "# Define a function to clean zero-width characters \n",
    "def clean(text):\n",
    "    return text.replace('\\u200b', '')\n",
    "\n",
    "# Define the import section as a string \n",
    "init_str = clean(\"\"\"\n",
    "# Core libraries\n",
    "import os                              # File and path operations\n",
    "import numpy as np                     # Numerical computations\n",
    "import pandas as pd                    # Data handling and analysis\n",
    "from tqdm import tqdm                  # Progress bars\n",
    "\n",
    "# Scikit-learn (data metrics)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Deep learning: TensorFlow + Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image                  # Pillow for image file handling\n",
    "\"\"\")\n",
    "\n",
    "# Write to a script file\n",
    "with open('model.py', 'w') as f:\n",
    "    \n",
    "    # Write the import section\n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Write the source code of required functions\n",
    "    for fn_name in [load_csv, get_file_path, load_data, create_model, train_model, model_eval]:\n",
    "        src = inspect.getsource(fn_name)\n",
    "        f.write(clean(src))  # Clean function body too\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "    # Write the main script logic\n",
    "    main_script = clean(\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    base_path = '/content/drive/MyDrive'  # change here if needed per environment\n",
    "    train_df, val_df, test_df = load_csv(base_path)\n",
    "\n",
    "    train_df['file_path'] = train_df['file_name'].apply(lambda x: get_file_path(base_path, 'train', x))\n",
    "    val_df['file_path'] = val_df['file_name'].apply(lambda x: get_file_path(base_path, 'valid', x))\n",
    "    test_df['file_path'] = test_df['file_name'].apply(lambda x: get_file_path(base_path, 'test', x))\n",
    "\n",
    "    train_ds, image_shape = load_data(train_df)\n",
    "    val_ds, _ = load_data(val_df)\n",
    "    test_ds, _ = load_data(test_df, shuffle=False)\n",
    "\n",
    "    model = create_model(image_shape)\n",
    "    train_model(model, train_ds, val_ds)\n",
    "\n",
    "    model_eval(model, test_df['real_age'], test_df['apparent_age_avg'])\n",
    "\"\"\")\n",
    "\n",
    "    f.write(main_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the output from the GPU platform as an Markdown cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "This is the output from the script I ran in google colab with A100 GPUs, not the output that was provided by the TTT platform, although I used the same model structure. The only difference with my model was that I used ModelCheckpoint() to leave the model with the parameters that performed best on the validation set during training. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/20\n",
    "129/129 - 382s - 3s/step - loss: 188.3276 - mae: 10.3624 - val_loss: 404.7741 - val_mae: 15.1994\n",
    "Epoch 2/20\n",
    "129/129 - 11s - 85ms/step - loss: 87.4498 - mae: 7.2506 - val_loss: 368.2730 - val_mae: 14.3708\n",
    "Epoch 3/20\n",
    "129/129 - 12s - 91ms/step - loss: 60.4758 - mae: 5.9903 - val_loss: 354.6083 - val_mae: 14.0227\n",
    "Epoch 4/20\n",
    "129/129 - 12s - 90ms/step - loss: 39.5704 - mae: 4.7526 - val_loss: 254.5890 - val_mae: 12.3463\n",
    "Epoch 5/20\n",
    "129/129 - 12s - 90ms/step - loss: 26.9462 - mae: 3.9868 - val_loss: 231.6930 - val_mae: 11.8536\n",
    "Epoch 6/20\n",
    "129/129 - 11s - 84ms/step - loss: 20.8511 - mae: 3.5217 - val_loss: 140.5745 - val_mae: 9.2435\n",
    "Epoch 7/20\n",
    "129/129 - 12s - 91ms/step - loss: 19.7864 - mae: 3.4079 - val_loss: 114.7309 - val_mae: 7.9518\n",
    "Epoch 8/20\n",
    "129/129 - 12s - 92ms/step - loss: 18.1562 - mae: 3.2287 - val_loss: 99.1776 - val_mae: 7.3540\n",
    "Epoch 9/20\n",
    "129/129 - 12s - 91ms/step - loss: 16.8994 - mae: 3.0925 - val_loss: 91.0080 - val_mae: 7.0221\n",
    "Epoch 10/20\n",
    "129/129 - 11s - 82ms/step - loss: 14.0554 - mae: 2.8471 - val_loss: 100.2822 - val_mae: 7.6958\n",
    "Epoch 11/20\n",
    "129/129 - 11s - 89ms/step - loss: 12.8367 - mae: 2.7504 - val_loss: 87.6442 - val_mae: 6.9339\n",
    "Epoch 12/20\n",
    "129/129 - 10s - 76ms/step - loss: 12.8009 - mae: 2.7349 - val_loss: 121.9496 - val_mae: 7.8613\n",
    "Epoch 13/20\n",
    "129/129 - 10s - 75ms/step - loss: 13.0961 - mae: 2.7409 - val_loss: 97.2528 - val_mae: 7.2666\n",
    "Epoch 14/20\n",
    "129/129 - 10s - 75ms/step - loss: 12.7429 - mae: 2.6085 - val_loss: 87.9459 - val_mae: 6.8886\n",
    "Epoch 15/20\n",
    "129/129 - 10s - 75ms/step - loss: 11.2712 - mae: 2.5433 - val_loss: 117.2740 - val_mae: 7.9199\n",
    "Epoch 16/20\n",
    "129/129 - 10s - 75ms/step - loss: 10.1002 - mae: 2.3800 - val_loss: 155.8389 - val_mae: 10.2878\n",
    "Epoch 17/20\n",
    "129/129 - 11s - 86ms/step - loss: 9.1066 - mae: 2.3045 - val_loss: 86.0609 - val_mae: 6.8119\n",
    "Epoch 18/20\n",
    "129/129 - 10s - 79ms/step - loss: 7.6095 - mae: 2.0997 - val_loss: 96.2923 - val_mae: 7.2657\n",
    "Epoch 19/20\n",
    "129/129 - 10s - 75ms/step - loss: 6.8119 - mae: 1.9936 - val_loss: 90.3570 - val_mae: 6.9667\n",
    "Epoch 20/20\n",
    "129/129 - 10s - 75ms/step - loss: 5.9435 - mae: 1.8791 - val_loss: 92.4066 - val_mae: 6.9797\n",
    "<Sequential name=sequential, built=True>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "   \n",
    "\n",
    "You can use Markdown cell for your code and results: \n",
    "\n",
    "    ```python\n",
    "    \n",
    "    # code\n",
    "    \n",
    "    \n",
    "    ```\n",
    "    \n",
    "Example:\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "Epoch 1/20\n",
    "356/356 - 35s - loss: 95.3532 - mae: 7.4339 - val_loss: 124.3362 - val_mae: 8.4921  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output shows that our model shows significant improvement early on. However, the model did not show consistent improvement throughout training. I added utilized the ModelCheckpoint() method for this reason. \n",
    "\n",
    "Our MAE on the trianing set was much better than on the validation set. This suggests there is some overfitting going on. Our model may benefit from the addition of some regularization techniques. I ran a couple of iterations utilizing dropout with little to no benefit. However, perhaps some l2 regularization could be beneficial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(model, test_df['real_age'], test_df['apparent_age_avg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_eval output:\n",
    "62/62 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2s 37ms/step - loss: 140.4368 - mae: 8.4980\n",
    "MAE for the model: 8.538291931152344\n",
    "MSE for the model: 141.1843719482422\n",
    "MAE human guess avg: 4.58948056502737\n",
    "MSE human guess avg: 41.15976503909733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model did not perform quite as well as the humans who estimated the ages in the photos for the Appa-Real database. This is okay if the goal is to reduce the workload of individuals. The model still offers potential benefit in flagging customers who are potentially under age. It just cannot have the final say. Also, it can help weed out unreliable employees if it repeatedly predicts ages under 21 for people whom the cashier willingly sells alcohol to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "    \n",
    "We can still think about further improvements. Sometimes it is possible to increase the dataset. What else can be done? Sometimes it may be helpful to try different data augmentation approaches. By the way, here's a good library [albumentations](https://github.com/albumentations-team/albumentations). Apart from this, we can consider introducing additional layers with some normalization methods. The optimization part is good. Adam is quite flexible, but you can still try other optimizers if you want. For example, AdamW sometimes shows better results. \n",
    "\n",
    "\n",
    "\n",
    "Regarding age verification, I would argue that we have some noticable limits here. It is much more reliable and much easier to just compare the id or passport photo to the customer's face. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ]  Notebook was opened\n",
    "- [ ]  The code is error free\n",
    "- [ ]  The cells with code have been arranged by order of execution\n",
    "- [ ]  The exploratory data analysis has been performed\n",
    "- [ ]  The results of the exploratory data analysis are presented in the final notebook\n",
    "- [ ]  The model's MAE score is not higher than 8\n",
    "- [ ]  The model training code has been copied to the final notebook\n",
    "- [ ]  The model training output has been copied to the final notebook\n",
    "- [ ]  The findings have been provided based on the results of the model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sprint_15_env)",
   "language": "python",
   "name": "sprint_15_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
